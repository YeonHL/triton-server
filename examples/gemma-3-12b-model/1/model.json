{
  "model": "google/gemma-3-12b-it",
  "task": "generate",
  "max_model_len": 8192,
  "pipeline_parallel_size": 1,
  "tensor_parallel_size": 1,
  "gpu_memory_utilization": 0.9,
  "max_num_seqs": 1,
  "disable_log_requests": "true"
}
